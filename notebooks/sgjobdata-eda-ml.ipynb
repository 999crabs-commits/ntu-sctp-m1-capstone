{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388f12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb666603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>employmentTypes</th>\n",
       "      <th>metadata_expiryDate</th>\n",
       "      <th>metadata_isPostedOnBehalf</th>\n",
       "      <th>metadata_jobPostId</th>\n",
       "      <th>metadata_newPostingDate</th>\n",
       "      <th>metadata_originalPostingDate</th>\n",
       "      <th>metadata_repostCount</th>\n",
       "      <th>metadata_totalNumberJobApplication</th>\n",
       "      <th>metadata_totalNumberOfView</th>\n",
       "      <th>...</th>\n",
       "      <th>occupationId</th>\n",
       "      <th>positionLevels</th>\n",
       "      <th>postedCompany_name</th>\n",
       "      <th>salary_maximum</th>\n",
       "      <th>salary_minimum</th>\n",
       "      <th>salary_type</th>\n",
       "      <th>status_id</th>\n",
       "      <th>status_jobStatus</th>\n",
       "      <th>title</th>\n",
       "      <th>average_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"id\":13,\"category\":\"Environment / Health\"},{...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0252866</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Executive</td>\n",
       "      <td>WORKSTONE PTE. LTD.</td>\n",
       "      <td>2800</td>\n",
       "      <td>2000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Food Technologist - Clementi | Entry Level | U...</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"id\":21,\"category\":\"Information Technology\"}]</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273977</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Executive</td>\n",
       "      <td>TRUST RECRUIT PTE. LTD.</td>\n",
       "      <td>5500</td>\n",
       "      <td>4000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Software Engineer (Fab Support) (Java, CIM, Up...</td>\n",
       "      <td>4750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"id\":33,\"category\":\"Repair and Maintenance\"}]</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273994</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>PU TIEN SERVICES PTE. LTD.</td>\n",
       "      <td>4600</td>\n",
       "      <td>3800</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Senior Technician</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"id\":21,\"category\":\"Information Technology\"}]</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273991</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>TRUST RECRUIT PTE. LTD.</td>\n",
       "      <td>10000</td>\n",
       "      <td>5000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Senior .NET Developer (.NET Core, MVC, MVVC, S...</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"id\":2,\"category\":\"Admin / Secretarial\"}]</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273976</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-executive</td>\n",
       "      <td>EATZ CATERING SERVICES PTE. LTD.</td>\n",
       "      <td>3400</td>\n",
       "      <td>2400</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Sales / Admin Cordinator</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories employmentTypes  \\\n",
       "0  [{\"id\":13,\"category\":\"Environment / Health\"},{...       Permanent   \n",
       "1    [{\"id\":21,\"category\":\"Information Technology\"}]       Permanent   \n",
       "2    [{\"id\":33,\"category\":\"Repair and Maintenance\"}]       Full Time   \n",
       "3    [{\"id\":21,\"category\":\"Information Technology\"}]       Permanent   \n",
       "4        [{\"id\":2,\"category\":\"Admin / Secretarial\"}]       Full Time   \n",
       "\n",
       "  metadata_expiryDate  metadata_isPostedOnBehalf metadata_jobPostId  \\\n",
       "0          2023-05-08                      False   MCF-2023-0252866   \n",
       "1          2023-05-08                      False   MCF-2023-0273977   \n",
       "2          2023-04-22                      False   MCF-2023-0273994   \n",
       "3          2023-05-08                      False   MCF-2023-0273991   \n",
       "4          2023-05-08                      False   MCF-2023-0273976   \n",
       "\n",
       "  metadata_newPostingDate metadata_originalPostingDate  metadata_repostCount  \\\n",
       "0              2023-04-08                   2023-03-30                     2   \n",
       "1              2023-04-08                   2023-04-08                     0   \n",
       "2              2023-04-08                   2023-04-08                     0   \n",
       "3              2023-04-08                   2023-04-08                     0   \n",
       "4              2023-04-08                   2023-04-08                     0   \n",
       "\n",
       "   metadata_totalNumberJobApplication  metadata_totalNumberOfView  ...  \\\n",
       "0                                   5                         151  ...   \n",
       "1                                   0                          55  ...   \n",
       "2                                   7                          99  ...   \n",
       "3                                   6                         113  ...   \n",
       "4                                   3                          99  ...   \n",
       "\n",
       "   occupationId    positionLevels                postedCompany_name  \\\n",
       "0           NaN         Executive               WORKSTONE PTE. LTD.   \n",
       "1           NaN         Executive           TRUST RECRUIT PTE. LTD.   \n",
       "2           NaN  Senior Executive        PU TIEN SERVICES PTE. LTD.   \n",
       "3           NaN  Senior Executive           TRUST RECRUIT PTE. LTD.   \n",
       "4           NaN     Non-executive  EATZ CATERING SERVICES PTE. LTD.   \n",
       "\n",
       "  salary_maximum salary_minimum  salary_type  status_id status_jobStatus  \\\n",
       "0           2800           2000      Monthly          0           Closed   \n",
       "1           5500           4000      Monthly          0           Closed   \n",
       "2           4600           3800      Monthly          0           Closed   \n",
       "3          10000           5000      Monthly          0           Closed   \n",
       "4           3400           2400      Monthly          0           Closed   \n",
       "\n",
       "                                               title average_salary  \n",
       "0  Food Technologist - Clementi | Entry Level | U...         2400.0  \n",
       "1  Software Engineer (Fab Support) (Java, CIM, Up...         4750.0  \n",
       "2                                  Senior Technician         4200.0  \n",
       "3  Senior .NET Developer (.NET Core, MVC, MVVC, S...         7500.0  \n",
       "4                           Sales / Admin Cordinator         2900.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv('../data/sgjobdata.csv.xz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c0c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert category in json format to a string format\n",
    "\n",
    "def categories_json_to_string(df, col=\"categories\", sep=\"; \"):\n",
    "    out = df.copy()\n",
    "\n",
    "    def parse_and_join(x):\n",
    "        if pd.isna(x):\n",
    "            return None\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                data = json.loads(x)\n",
    "            except json.JSONDecodeError:\n",
    "                return None\n",
    "        else:\n",
    "            data = x\n",
    "\n",
    "        if isinstance(data, list):\n",
    "            return sep.join(\n",
    "                d.get(\"category\") for d in data\n",
    "                if isinstance(d, dict) and \"category\" in d\n",
    "            )\n",
    "\n",
    "        return None\n",
    "\n",
    "    out[col] = out[col].map(parse_and_join)\n",
    "    return out\n",
    "\n",
    "###\n",
    "def clean_title_light(t: str) -> str:\n",
    "    t = (t or \"\").strip().lower()\n",
    "    # Keep bracket content, seniority, domain hints; remove only separators/noisy symbols\n",
    "    t = re.sub(r\"[_#|]+\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf65688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1048585 entries, 0 to 1048584\n",
      "Data columns (total 22 columns):\n",
      " #   Column                              Non-Null Count    Dtype  \n",
      "---  ------                              --------------    -----  \n",
      " 0   categories                          1044597 non-null  str    \n",
      " 1   employmentTypes                     1044597 non-null  str    \n",
      " 2   metadata_expiryDate                 1044597 non-null  str    \n",
      " 3   metadata_isPostedOnBehalf           1048585 non-null  bool   \n",
      " 4   metadata_jobPostId                  1044597 non-null  str    \n",
      " 5   metadata_newPostingDate             1044597 non-null  str    \n",
      " 6   metadata_originalPostingDate        1044597 non-null  str    \n",
      " 7   metadata_repostCount                1048585 non-null  int64  \n",
      " 8   metadata_totalNumberJobApplication  1048585 non-null  int64  \n",
      " 9   metadata_totalNumberOfView          1048585 non-null  int64  \n",
      " 10  minimumYearsExperience              1048585 non-null  int64  \n",
      " 11  numberOfVacancies                   1048585 non-null  int64  \n",
      " 12  occupationId                        0 non-null        float64\n",
      " 13  positionLevels                      1044597 non-null  str    \n",
      " 14  postedCompany_name                  1044597 non-null  str    \n",
      " 15  salary_maximum                      1048585 non-null  int64  \n",
      " 16  salary_minimum                      1048585 non-null  int64  \n",
      " 17  salary_type                         1044597 non-null  str    \n",
      " 18  status_id                           1048585 non-null  int64  \n",
      " 19  status_jobStatus                    1044597 non-null  str    \n",
      " 20  title                               1044597 non-null  str    \n",
      " 21  average_salary                      1048585 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(8), str(11)\n",
      "memory usage: 383.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>employmentTypes</th>\n",
       "      <th>metadata_expiryDate</th>\n",
       "      <th>metadata_isPostedOnBehalf</th>\n",
       "      <th>metadata_jobPostId</th>\n",
       "      <th>metadata_newPostingDate</th>\n",
       "      <th>metadata_originalPostingDate</th>\n",
       "      <th>metadata_repostCount</th>\n",
       "      <th>metadata_totalNumberJobApplication</th>\n",
       "      <th>metadata_totalNumberOfView</th>\n",
       "      <th>...</th>\n",
       "      <th>positionLevels</th>\n",
       "      <th>postedCompany_name</th>\n",
       "      <th>salary_maximum</th>\n",
       "      <th>salary_minimum</th>\n",
       "      <th>salary_type</th>\n",
       "      <th>status_id</th>\n",
       "      <th>status_jobStatus</th>\n",
       "      <th>title</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>title_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environment / Health; Manufacturing; Sciences ...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0252866</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>Executive</td>\n",
       "      <td>WORKSTONE PTE. LTD.</td>\n",
       "      <td>2800</td>\n",
       "      <td>2000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Food Technologist - Clementi | Entry Level | U...</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>food technologist - clementi entry level up to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273977</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>Executive</td>\n",
       "      <td>TRUST RECRUIT PTE. LTD.</td>\n",
       "      <td>5500</td>\n",
       "      <td>4000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Software Engineer (Fab Support) (Java, CIM, Up...</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>software engineer (fab support) (java, cim, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Repair and Maintenance</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273994</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>PU TIEN SERVICES PTE. LTD.</td>\n",
       "      <td>4600</td>\n",
       "      <td>3800</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Senior Technician</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>senior technician-repair and maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273991</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>TRUST RECRUIT PTE. LTD.</td>\n",
       "      <td>10000</td>\n",
       "      <td>5000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Senior .NET Developer (.NET Core, MVC, MVVC, S...</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>senior .net developer (.net core, mvc, mvvc, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admin / Secretarial</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273976</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>Non-executive</td>\n",
       "      <td>EATZ CATERING SERVICES PTE. LTD.</td>\n",
       "      <td>3400</td>\n",
       "      <td>2400</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Sales / Admin Cordinator</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>sales / admin cordinator-admin / secretarial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories employmentTypes  \\\n",
       "0  Environment / Health; Manufacturing; Sciences ...       Permanent   \n",
       "1                             Information Technology       Permanent   \n",
       "2                             Repair and Maintenance       Full Time   \n",
       "3                             Information Technology       Permanent   \n",
       "4                                Admin / Secretarial       Full Time   \n",
       "\n",
       "  metadata_expiryDate  metadata_isPostedOnBehalf metadata_jobPostId  \\\n",
       "0          2023-05-08                      False   MCF-2023-0252866   \n",
       "1          2023-05-08                      False   MCF-2023-0273977   \n",
       "2          2023-04-22                      False   MCF-2023-0273994   \n",
       "3          2023-05-08                      False   MCF-2023-0273991   \n",
       "4          2023-05-08                      False   MCF-2023-0273976   \n",
       "\n",
       "  metadata_newPostingDate metadata_originalPostingDate  metadata_repostCount  \\\n",
       "0              2023-04-08                   2023-03-30                     2   \n",
       "1              2023-04-08                   2023-04-08                     0   \n",
       "2              2023-04-08                   2023-04-08                     0   \n",
       "3              2023-04-08                   2023-04-08                     0   \n",
       "4              2023-04-08                   2023-04-08                     0   \n",
       "\n",
       "   metadata_totalNumberJobApplication  metadata_totalNumberOfView  ...  \\\n",
       "0                                   5                         151  ...   \n",
       "1                                   0                          55  ...   \n",
       "2                                   7                          99  ...   \n",
       "3                                   6                         113  ...   \n",
       "4                                   3                          99  ...   \n",
       "\n",
       "     positionLevels                postedCompany_name  salary_maximum  \\\n",
       "0         Executive               WORKSTONE PTE. LTD.            2800   \n",
       "1         Executive           TRUST RECRUIT PTE. LTD.            5500   \n",
       "2  Senior Executive        PU TIEN SERVICES PTE. LTD.            4600   \n",
       "3  Senior Executive           TRUST RECRUIT PTE. LTD.           10000   \n",
       "4     Non-executive  EATZ CATERING SERVICES PTE. LTD.            3400   \n",
       "\n",
       "  salary_minimum salary_type  status_id  status_jobStatus  \\\n",
       "0           2000     Monthly          0            Closed   \n",
       "1           4000     Monthly          0            Closed   \n",
       "2           3800     Monthly          0            Closed   \n",
       "3           5000     Monthly          0            Closed   \n",
       "4           2400     Monthly          0            Closed   \n",
       "\n",
       "                                               title  average_salary  \\\n",
       "0  Food Technologist - Clementi | Entry Level | U...          2400.0   \n",
       "1  Software Engineer (Fab Support) (Java, CIM, Up...          4750.0   \n",
       "2                                  Senior Technician          4200.0   \n",
       "3  Senior .NET Developer (.NET Core, MVC, MVVC, S...          7500.0   \n",
       "4                           Sales / Admin Cordinator          2900.0   \n",
       "\n",
       "                                      title_analysis  \n",
       "0  food technologist - clementi entry level up to...  \n",
       "1  software engineer (fab support) (java, cim, up...  \n",
       "2           senior technician-repair and maintenance  \n",
       "3  senior .net developer (.net core, mvc, mvvc, s...  \n",
       "4       sales / admin cordinator-admin / secretarial  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df_categories_str = categories_json_to_string(df)\n",
    "df_categories_str = df_categories_str.dropna(subset=[\"title\"])\n",
    "df_categories_str[\"title_analysis\"] = df_categories_str[\"title\"] + \"-\" + df_categories_str[\"categories\"]\n",
    "df_categories_str[\"title_analysis\"] = df_categories_str[\"title_analysis\"].map(clean_title_light)\n",
    "df_categories_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fcf42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employmentTypes</th>\n",
       "      <th>metadata_expiryDate</th>\n",
       "      <th>metadata_isPostedOnBehalf</th>\n",
       "      <th>metadata_jobPostId</th>\n",
       "      <th>metadata_newPostingDate</th>\n",
       "      <th>metadata_originalPostingDate</th>\n",
       "      <th>metadata_repostCount</th>\n",
       "      <th>metadata_totalNumberJobApplication</th>\n",
       "      <th>metadata_totalNumberOfView</th>\n",
       "      <th>minimumYearsExperience</th>\n",
       "      <th>...</th>\n",
       "      <th>postedCompany_name</th>\n",
       "      <th>salary_maximum</th>\n",
       "      <th>salary_minimum</th>\n",
       "      <th>salary_type</th>\n",
       "      <th>status_id</th>\n",
       "      <th>status_jobStatus</th>\n",
       "      <th>title</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0252866</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>WORKSTONE PTE. LTD.</td>\n",
       "      <td>2800</td>\n",
       "      <td>2000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Food Technologist - Clementi | Entry Level | U...</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Environment / Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0252866</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>WORKSTONE PTE. LTD.</td>\n",
       "      <td>2800</td>\n",
       "      <td>2000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Food Technologist - Clementi | Entry Level | U...</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0252866</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>WORKSTONE PTE. LTD.</td>\n",
       "      <td>2800</td>\n",
       "      <td>2000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Food Technologist - Clementi | Entry Level | U...</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Sciences / Laboratory / R&amp;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Permanent</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273977</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>TRUST RECRUIT PTE. LTD.</td>\n",
       "      <td>5500</td>\n",
       "      <td>4000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Software Engineer (Fab Support) (Java, CIM, Up...</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Time</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>False</td>\n",
       "      <td>MCF-2023-0273994</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>PU TIEN SERVICES PTE. LTD.</td>\n",
       "      <td>4600</td>\n",
       "      <td>3800</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Senior Technician</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Repair and Maintenance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  employmentTypes metadata_expiryDate  metadata_isPostedOnBehalf  \\\n",
       "0       Permanent          2023-05-08                      False   \n",
       "1       Permanent          2023-05-08                      False   \n",
       "2       Permanent          2023-05-08                      False   \n",
       "3       Permanent          2023-05-08                      False   \n",
       "4       Full Time          2023-04-22                      False   \n",
       "\n",
       "  metadata_jobPostId metadata_newPostingDate metadata_originalPostingDate  \\\n",
       "0   MCF-2023-0252866              2023-04-08                   2023-03-30   \n",
       "1   MCF-2023-0252866              2023-04-08                   2023-03-30   \n",
       "2   MCF-2023-0252866              2023-04-08                   2023-03-30   \n",
       "3   MCF-2023-0273977              2023-04-08                   2023-04-08   \n",
       "4   MCF-2023-0273994              2023-04-08                   2023-04-08   \n",
       "\n",
       "   metadata_repostCount  metadata_totalNumberJobApplication  \\\n",
       "0                     2                                   5   \n",
       "1                     2                                   5   \n",
       "2                     2                                   5   \n",
       "3                     0                                   0   \n",
       "4                     0                                   7   \n",
       "\n",
       "   metadata_totalNumberOfView  minimumYearsExperience  ...  \\\n",
       "0                         151                       0  ...   \n",
       "1                         151                       0  ...   \n",
       "2                         151                       0  ...   \n",
       "3                          55                       2  ...   \n",
       "4                          99                       3  ...   \n",
       "\n",
       "           postedCompany_name  salary_maximum salary_minimum salary_type  \\\n",
       "0         WORKSTONE PTE. LTD.            2800           2000     Monthly   \n",
       "1         WORKSTONE PTE. LTD.            2800           2000     Monthly   \n",
       "2         WORKSTONE PTE. LTD.            2800           2000     Monthly   \n",
       "3     TRUST RECRUIT PTE. LTD.            5500           4000     Monthly   \n",
       "4  PU TIEN SERVICES PTE. LTD.            4600           3800     Monthly   \n",
       "\n",
       "   status_id  status_jobStatus  \\\n",
       "0          0            Closed   \n",
       "1          0            Closed   \n",
       "2          0            Closed   \n",
       "3          0            Closed   \n",
       "4          0            Closed   \n",
       "\n",
       "                                               title  average_salary  \\\n",
       "0  Food Technologist - Clementi | Entry Level | U...          2400.0   \n",
       "1  Food Technologist - Clementi | Entry Level | U...          2400.0   \n",
       "2  Food Technologist - Clementi | Entry Level | U...          2400.0   \n",
       "3  Software Engineer (Fab Support) (Java, CIM, Up...          4750.0   \n",
       "4                                  Senior Technician          4200.0   \n",
       "\n",
       "  category_id                     category  \n",
       "0        13.0         Environment / Health  \n",
       "1        25.0                Manufacturing  \n",
       "2        36.0  Sciences / Laboratory / R&D  \n",
       "3        21.0       Information Technology  \n",
       "4        33.0       Repair and Maintenance  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explode_categories(df, col=\"categories\"):\n",
    "    out = df.copy()\n",
    "\n",
    "    out[col] = (\n",
    "        out[col]\n",
    "        .dropna()\n",
    "        .map(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "    )\n",
    "\n",
    "    out = out.explode(col, ignore_index=True)\n",
    "\n",
    "    out[\"category_id\"] = out[col].map(lambda d: d.get(\"id\") if isinstance(d, dict) else None)\n",
    "    out[\"category\"]    = out[col].map(lambda d: d.get(\"category\") if isinstance(d, dict) else None)\n",
    "\n",
    "    return out.drop(columns=[col])\n",
    "\n",
    "df_exploded = explode_categories(df)\n",
    "df_exploded = df_exploded.dropna(subset=[\"category_id\", \"category\"])\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if company name contains 'kpmg', show list of such rows\n",
    "df_exploded[df_exploded['postedCompany_name'].str.contains('kpmg', case=False, na=False)].sort_values('metadata_originalPostingDate', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eaf001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[df_exploded['category'] == 'Accounting / Auditing / Taxation'][['category','postedCompany_name','metadata_jobPostId','numberOfVacancies']] \\\n",
    "    .groupby('postedCompany_name').numberOfVacancies.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58109dc2",
   "metadata": {},
   "source": [
    "## CLean Job Title data & use it to predict top 3 skillsets using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    pipeline,\n",
    ")\n",
    "from transformers.pipelines import PIPELINE_REGISTRY\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# A) Cleaning (minimal, preserve nuance)\n",
    "# ============================================================\n",
    "def clean_title_light(t: str) -> str:\n",
    "    t = (t or \"\").strip().lower()\n",
    "    # Keep bracket content, seniority, domain hints; remove only separators/noisy symbols\n",
    "    t = re.sub(r\"[_#|]+\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# B) Embedding + scalable \"loose\" clustering\n",
    "# ============================================================\n",
    "def embed_unique_titles(unique_titles: list[str],\n",
    "                        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                        device: str = \"cpu\",\n",
    "                        batch_size: int = 256) -> np.ndarray:\n",
    "    embedder = SentenceTransformer(model_name, device=device)\n",
    "    emb = embedder.encode(\n",
    "        unique_titles,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    return emb\n",
    "\n",
    "\n",
    "def cluster_embeddings_loose(embeddings: np.ndarray,\n",
    "                             n_clusters: int = 800,\n",
    "                             batch_size: int = 8192,\n",
    "                             random_state: int = 42) -> np.ndarray:\n",
    "    km = MiniBatchKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        batch_size=batch_size,\n",
    "        random_state=random_state,\n",
    "        n_init=\"auto\"\n",
    "    )\n",
    "    return km.fit_predict(embeddings)\n",
    "\n",
    "\n",
    "def canonical_title_per_cluster(u: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    u must contain: job_title_cleaned, cluster_id, count\n",
    "    Returns canonical mapping: cluster_id -> clustered_job_title (most frequent in cluster)\n",
    "    \"\"\"\n",
    "    canon = (\n",
    "        u.sort_values([\"cluster_id\", \"count\"], ascending=[True, False])\n",
    "         .groupby(\"cluster_id\", as_index=False)\n",
    "         .head(1)[[\"cluster_id\", \"job_title_cleaned\"]]\n",
    "         .rename(columns={\"job_title_cleaned\": \"clustered_job_title\"})\n",
    "    )\n",
    "    return canon\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# C) LLM backend (supports seq2seq and causal, robust)\n",
    "# ============================================================\n",
    "def _supports_pipeline(task_name: str) -> bool:\n",
    "    try:\n",
    "        PIPELINE_REGISTRY.check_task(task_name)\n",
    "        return True\n",
    "    except KeyError:\n",
    "        return False\n",
    "\n",
    "\n",
    "class SkillInferencer:\n",
    "    \"\"\"\n",
    "    A robust local inferencer that works on Mac CPU:\n",
    "    - Supports causal instruct models (text-generation)\n",
    "    - Supports seq2seq models (Flan-T5) using pipeline if available,\n",
    "      otherwise uses direct model.generate() to avoid pipeline task errors.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hf_model_name: str,\n",
    "                 backend: str = \"auto\",  # \"auto\" | \"seq2seq\" | \"causal\"\n",
    "                 device: str | None = None):\n",
    "        self.hf_model_name = hf_model_name\n",
    "        self.backend = backend\n",
    "        self.device = device  # \"cpu\" or \"cuda\" (we assume cpu on M1)\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.gen_pipe = None\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        cfg = AutoConfig.from_pretrained(self.hf_model_name)\n",
    "        model_type = getattr(cfg, \"model_type\", \"\").lower()\n",
    "\n",
    "        if self.backend == \"auto\":\n",
    "            # Heuristic: t5/mt5/bart/pegasus => seq2seq; else causal\n",
    "            if model_type in {\"t5\", \"mt5\", \"bart\", \"mbart\", \"pegasus\"}:\n",
    "                self.backend = \"seq2seq\"\n",
    "            else:\n",
    "                self.backend = \"causal\"\n",
    "\n",
    "        if self.device is None:\n",
    "            # M1: CPU\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.hf_model_name)\n",
    "\n",
    "        if self.backend == \"seq2seq\":\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.hf_model_name)\n",
    "            self.model.to(self.device)\n",
    "            # Use pipeline only if task exists; otherwise we use generate() directly\n",
    "            if _supports_pipeline(\"text2text-generation\"):\n",
    "                pipe_device = 0 if self.device == \"cuda\" else -1\n",
    "                self.gen_pipe = pipeline(\n",
    "                    \"text2text-generation\",\n",
    "                    model=self.model,\n",
    "                    tokenizer=self.tokenizer,\n",
    "                    device=pipe_device\n",
    "                )\n",
    "            else:\n",
    "                self.gen_pipe = None\n",
    "\n",
    "        elif self.backend == \"causal\":\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.hf_model_name,\n",
    "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "            )\n",
    "            self.model.to(self.device)\n",
    "            pipe_device = 0 if self.device == \"cuda\" else -1\n",
    "            self.gen_pipe = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer,\n",
    "                device=pipe_device\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"backend must be 'auto', 'seq2seq', or 'causal'\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _prompt(title: str) -> str:\n",
    "        return (\n",
    "            \"Return JSON only.\\n\"\n",
    "            \"Task: Infer the top 5 core skills required for the job title.\\n\"\n",
    "            f\"Job title: {title}\\n\"\n",
    "            \"Rules:\\n\"\n",
    "            \"- Exactly 5 skills\\n\"\n",
    "            \"- Short noun phrases (1–3 words)\\n\"\n",
    "            \"- No explanation\\n\"\n",
    "            'JSON schema: {\"skills\":[\"skill1\",\"skill2\",\"skill3\",\"skill4\",\"skill5\"]}'\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_json(text: str) -> dict:\n",
    "        # First try: extract first {...}\n",
    "        s = text.find(\"{\")\n",
    "        e = text.rfind(\"}\") + 1\n",
    "        if s != -1 and e != -1 and e > s:\n",
    "            candidate = text[s:e]\n",
    "            try:\n",
    "                obj = json.loads(candidate)\n",
    "                skills = obj.get(\"skills\", [])\n",
    "                if isinstance(skills, list):\n",
    "                    skills = [re.sub(r\"\\s+\", \" \", str(x).strip()) for x in skills if str(x).strip()]\n",
    "                    skills = skills[:5]\n",
    "                    while len(skills) < 5:\n",
    "                        skills.append(\"unknown\")\n",
    "                    return {\"skills\": skills}\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Fallback: pull quoted strings\n",
    "        items = [x for x in re.findall(r'\"([^\"]+)\"', text) if x.lower() != \"skills\"]\n",
    "        items = [re.sub(r\"\\s+\", \" \", x.strip()) for x in items if x.strip()]\n",
    "        items = items[:5]\n",
    "        while len(items) < 5:\n",
    "            items.append(\"unknown\")\n",
    "        return {\"skills\": items}\n",
    "\n",
    "    def infer(self, title: str, max_new_tokens: int = 80) -> dict:\n",
    "        prompt = self._prompt(title)\n",
    "\n",
    "        if self.backend == \"causal\":\n",
    "            out = self.gen_pipe(\n",
    "                prompt,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                temperature=0.0,\n",
    "                return_full_text=False\n",
    "            )[0][\"generated_text\"]\n",
    "            return self._parse_json(out)\n",
    "\n",
    "        # seq2seq\n",
    "        if self.gen_pipe is not None:\n",
    "            out = self.gen_pipe(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0][\"generated_text\"]\n",
    "            return self._parse_json(out)\n",
    "\n",
    "        # seq2seq fallback: direct generate() (avoids pipeline task errors)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            gen_ids = self.model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "        out = self.tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "        return self._parse_json(out)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# D) End-to-end scalable function (1M rows safe)\n",
    "# ============================================================\n",
    "def build_title_skill_table(\n",
    "    df: pd.DataFrame,\n",
    "    raw_col: str,\n",
    "    # embedding\n",
    "    embed_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    embed_device: str = \"cpu\",\n",
    "    embed_batch_size: int = 256,\n",
    "    # clustering\n",
    "    n_clusters: int = 800,\n",
    "    km_batch_size: int = 8192,\n",
    "    # HF model\n",
    "    hf_model_name: str = \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    llm_backend: str = \"auto\",         # \"auto\"|\"causal\"|\"seq2seq\"\n",
    "    skills_per: str = \"cluster\",       # \"cluster\" recommended\n",
    "    # performance\n",
    "    max_new_tokens: int = 60,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Output columns (exactly):\n",
    "    a. job_title_raw (pre-clean)\n",
    "    b. job_title_cleaned\n",
    "    c. clustered_job_title\n",
    "    d. top_3_skills_json (dict)\n",
    "    \"\"\"\n",
    "    if raw_col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {raw_col}\")\n",
    "    if skills_per not in {\"cluster\", \"unique_title\"}:\n",
    "        raise ValueError(\"skills_per must be 'cluster' or 'unique_title'\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 1) Clean\n",
    "    df_work = df.copy()\n",
    "    df_work[\"job_title_cleaned\"] = df_work[raw_col].map(clean_title_light)\n",
    "\n",
    "    # 2) Unique + freq (for canonical titles)\n",
    "    u = (\n",
    "        df_work.groupby(\"job_title_cleaned\")\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    unique_titles = u[\"job_title_cleaned\"].tolist()\n",
    "\n",
    "    print(f\"Rows: {len(df_work):,}\")\n",
    "    print(f\"Unique cleaned titles: {len(unique_titles):,}\")\n",
    "\n",
    "    # 3) Embed uniques\n",
    "    print(\"\\n[1/4] Embedding unique titles...\")\n",
    "    emb = embed_unique_titles(unique_titles, embed_model_name, embed_device, embed_batch_size)\n",
    "    print(\"Embeddings:\", emb.shape, emb.dtype)\n",
    "\n",
    "    # 4) Cluster uniques\n",
    "    print(\"\\n[2/4] Clustering (MiniBatchKMeans)...\")\n",
    "    u[\"cluster_id\"] = cluster_embeddings_loose(emb, n_clusters=n_clusters, batch_size=km_batch_size)\n",
    "\n",
    "    # 5) Canonical per cluster\n",
    "    canon = canonical_title_per_cluster(u)\n",
    "    u = u.merge(canon, on=\"cluster_id\", how=\"left\")\n",
    "\n",
    "    # 6) Load local LLM backend\n",
    "    print(\"\\n[3/4] Loading local HF model...\")\n",
    "    inferencer = SkillInferencer(hf_model_name=hf_model_name, backend=llm_backend, device=None)\n",
    "    print(\"LLM backend selected:\", inferencer.backend)\n",
    "\n",
    "    # 7) Decide inference targets\n",
    "    if skills_per == \"cluster\":\n",
    "        targets = canon[\"clustered_job_title\"].drop_duplicates().tolist()\n",
    "        key_col = \"clustered_job_title\"\n",
    "        print(f\"Skill inference targets (clusters): {len(targets):,}\")\n",
    "    else:\n",
    "        targets = unique_titles\n",
    "        key_col = \"job_title_cleaned\"\n",
    "        print(f\"Skill inference targets (unique titles): {len(targets):,}\")\n",
    "\n",
    "    # 8) Infer skills once per target (cache)\n",
    "    print(\"\\n[4/4] Inferring top-5 skills (cached)...\")\n",
    "    cache = {}\n",
    "    for t in tqdm(targets):\n",
    "        if t not in cache:\n",
    "            cache[t] = inferencer.infer(t, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    u[\"top_5_skills_json\"] = u[key_col].map(cache)\n",
    "\n",
    "    # 9) Map back to 1M rows\n",
    "    df_out = df_work.merge(\n",
    "        u[[\"job_title_cleaned\", \"cluster_id\", \"clustered_job_title\", \"top_3_skills_json\"]],\n",
    "        on=\"job_title_cleaned\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df_out = df_out[[raw_col, \"job_title_cleaned\", \"clustered_job_title\", \"top_3_skills_json\"]].rename(\n",
    "        columns={raw_col: \"job_title_raw\"}\n",
    "    )\n",
    "\n",
    "    print(f\"\\nDone. Total seconds: {round(time.time() - t0, 1)}\")\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# E) Run a fail-fast small test first\n",
    "# ============================================================\n",
    "def sanity_test(df: pd.DataFrame, raw_col: str) -> pd.DataFrame:\n",
    "    small = df[[raw_col]].dropna().head(50).copy()\n",
    "    return build_title_skill_table(\n",
    "        df=small,\n",
    "        raw_col=raw_col,\n",
    "        n_clusters=10,\n",
    "        skills_per=\"cluster\",\n",
    "        hf_model_name=\"Qwen/Qwen2.5-0.5B-Instruct\",  # fast\n",
    "        llm_backend=\"causal\",\n",
    "        max_new_tokens=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "519c2747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 211/300 [1:01:55<1:30:27, 60.99s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 71%|███████   | 212/300 [1:02:09<1:08:39, 46.81s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 71%|███████   | 213/300 [1:02:22<53:08, 36.65s/it]  Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 71%|███████▏  | 214/300 [1:02:36<42:38, 29.75s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 72%|███████▏  | 215/300 [1:02:49<35:19, 24.93s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 72%|███████▏  | 216/300 [1:03:03<30:13, 21.59s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 72%|███████▏  | 217/300 [1:03:17<26:36, 19.24s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 73%|███████▎  | 218/300 [1:03:28<22:59, 16.83s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 73%|███████▎  | 219/300 [1:03:42<21:26, 15.89s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 73%|███████▎  | 220/300 [1:03:55<20:13, 15.17s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 74%|███████▎  | 221/300 [1:04:09<19:26, 14.76s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 74%|███████▍  | 222/300 [1:04:23<18:47, 14.45s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 74%|███████▍  | 223/300 [1:04:36<18:14, 14.21s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 75%|███████▍  | 224/300 [1:04:50<17:50, 14.08s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 75%|███████▌  | 225/300 [1:05:04<17:27, 13.97s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 75%|███████▌  | 226/300 [1:05:17<16:57, 13.74s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 76%|███████▌  | 227/300 [1:05:31<16:42, 13.73s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 76%|███████▌  | 228/300 [1:05:44<16:12, 13.51s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 76%|███████▋  | 229/300 [1:05:57<15:57, 13.49s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 77%|███████▋  | 230/300 [1:06:11<15:52, 13.60s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 77%|███████▋  | 231/300 [1:06:22<14:53, 12.95s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 77%|███████▋  | 232/300 [1:06:36<14:55, 13.18s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 78%|███████▊  | 233/300 [1:06:49<14:39, 13.13s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 78%|███████▊  | 234/300 [1:07:03<14:38, 13.30s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 78%|███████▊  | 235/300 [1:07:17<14:34, 13.45s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 79%|███████▊  | 236/300 [1:07:31<14:27, 13.55s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 79%|███████▉  | 237/300 [1:07:44<14:18, 13.63s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 79%|███████▉  | 238/300 [1:07:58<14:05, 13.64s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 80%|███████▉  | 239/300 [1:08:10<13:19, 13.11s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 80%|████████  | 240/300 [1:08:23<13:03, 13.05s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 80%|████████  | 241/300 [1:08:36<13:01, 13.24s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 81%|████████  | 242/300 [1:08:50<12:54, 13.36s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 81%|████████  | 243/300 [1:09:02<12:24, 13.06s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 81%|████████▏ | 244/300 [1:09:16<12:22, 13.26s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 82%|████████▏ | 245/300 [1:09:30<12:20, 13.46s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 82%|████████▏ | 246/300 [1:09:44<12:12, 13.57s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 82%|████████▏ | 247/300 [1:09:58<11:59, 13.57s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 83%|████████▎ | 248/300 [1:10:11<11:48, 13.62s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 83%|████████▎ | 249/300 [1:10:25<11:35, 13.65s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 83%|████████▎ | 250/300 [1:10:37<10:56, 13.12s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 84%|████████▎ | 251/300 [1:10:49<10:26, 12.78s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 84%|████████▍ | 252/300 [1:11:01<10:03, 12.57s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 84%|████████▍ | 253/300 [1:11:13<09:47, 12.49s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 85%|████████▍ | 254/300 [1:11:27<09:50, 12.84s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 85%|████████▌ | 255/300 [1:11:40<09:40, 12.90s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 85%|████████▌ | 256/300 [1:11:53<09:30, 12.96s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 86%|████████▌ | 257/300 [1:12:05<09:09, 12.77s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 86%|████████▌ | 258/300 [1:12:16<08:28, 12.10s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 86%|████████▋ | 259/300 [1:12:29<08:22, 12.27s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 87%|████████▋ | 260/300 [1:12:42<08:21, 12.54s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 87%|████████▋ | 261/300 [1:12:56<08:26, 12.98s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 87%|████████▋ | 262/300 [1:13:10<08:22, 13.22s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 88%|████████▊ | 263/300 [1:13:23<08:14, 13.37s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 88%|████████▊ | 264/300 [1:13:36<07:49, 13.05s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 88%|████████▊ | 265/300 [1:13:48<07:32, 12.94s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 89%|████████▊ | 266/300 [1:14:01<07:12, 12.73s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 89%|████████▉ | 267/300 [1:14:13<07:01, 12.78s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 89%|████████▉ | 268/300 [1:14:27<06:58, 13.08s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 90%|████████▉ | 269/300 [1:14:41<06:50, 13.24s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 90%|█████████ | 270/300 [1:14:55<06:44, 13.48s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 90%|█████████ | 271/300 [1:15:06<06:15, 12.93s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 91%|█████████ | 272/300 [1:15:20<06:08, 13.16s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 91%|█████████ | 273/300 [1:15:34<05:59, 13.33s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 91%|█████████▏| 274/300 [1:15:48<05:49, 13.43s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 92%|█████████▏| 275/300 [1:15:59<05:18, 12.74s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 92%|█████████▏| 276/300 [1:16:12<05:08, 12.86s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 92%|█████████▏| 277/300 [1:16:25<04:54, 12.82s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 93%|█████████▎| 278/300 [1:16:38<04:47, 13.08s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 93%|█████████▎| 279/300 [1:16:52<04:38, 13.28s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 93%|█████████▎| 280/300 [1:17:06<04:28, 13.45s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 94%|█████████▎| 281/300 [1:17:20<04:17, 13.53s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 94%|█████████▍| 282/300 [1:17:33<04:04, 13.59s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 94%|█████████▍| 283/300 [1:17:47<03:51, 13.64s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 95%|█████████▍| 284/300 [1:18:00<03:33, 13.33s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 95%|█████████▌| 285/300 [1:18:14<03:22, 13.48s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 95%|█████████▌| 286/300 [1:18:27<03:09, 13.56s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 96%|█████████▌| 287/300 [1:18:39<02:50, 13.15s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 96%|█████████▌| 288/300 [1:18:53<02:39, 13.33s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 96%|█████████▋| 289/300 [1:19:01<02:09, 11.74s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 97%|█████████▋| 290/300 [1:19:15<02:03, 12.36s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 97%|█████████▋| 291/300 [1:19:29<01:55, 12.78s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 97%|█████████▋| 292/300 [1:19:41<01:41, 12.64s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 98%|█████████▊| 293/300 [1:19:54<01:29, 12.75s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 98%|█████████▊| 294/300 [1:20:08<01:18, 13.05s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 98%|█████████▊| 295/300 [1:20:18<01:01, 12.23s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 99%|█████████▊| 296/300 [1:20:32<00:50, 12.71s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 99%|█████████▉| 297/300 [1:20:46<00:38, 13.00s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      " 99%|█████████▉| 298/300 [1:20:58<00:25, 12.79s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "100%|█████████▉| 299/300 [1:21:11<00:12, 12.75s/it]Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "100%|██████████| 300/300 [1:21:24<00:00, 16.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Total seconds: 5195.5\n"
     ]
    }
   ],
   "source": [
    "_ = sanity_test(df_categories_str, raw_col=\"title_analysis\")\n",
    "\n",
    "df_out = build_title_skill_table(\n",
    "    df=df_categories_str,\n",
    "    raw_col=\"title_analysis\",\n",
    "    n_clusters=300,                 # 50 is too coarse for real job titles\n",
    "    skills_per=\"cluster\",\n",
    "    hf_model_name=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    llm_backend=\"causal\",\n",
    "    max_new_tokens=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e694aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_parquet('sgjobdata_titleskills_v2_5skills.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0cd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
